<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Project 5: Fun with Diffusion Models</title>
<style>
body {
font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
margin: 0;
padding: 2rem;
background: #fafafa;
color: #222;
}
h1, h2, h3 {
margin-top: 2rem;
margin-bottom: 0.5rem;
}
h1 {
text-align: center;
}
section {
margin-bottom: 2rem;
padding: 1.5rem;
background: #fff;
border-radius: 8px;
box-shadow: 0 1px 3px rgba(0,0,0,0.06);
}
.subsection {
margin-top: 1rem;
margin-bottom: 1rem;
padding-top: 0.5rem;
border-top: 1px solid #eee;
}
figure {
margin: 1rem 0;
display: inline-block;
text-align: center;
}
figure img {
max-width: 280px;
border-radius: 6px;
border: 1px solid #ddd;
}
figure figcaption {
font-size: 0.9rem;
color: #555;
margin-top: 0.35rem;
}
.image-row {
display: flex;
flex-wrap: wrap;
gap: 1rem;
}
pre {
background: #111;
color: #f1f1f1;
padding: 0.75rem 1rem;
border-radius: 6px;
overflow-x: auto;
font-size: 0.9rem;
}
code {
font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
}
.note {
font-size: 0.9rem;
color: #666;
margin-top: 0.25rem;
}
</style>
</head>
<body>

<h1>Project 5: Fun with Diffusion Models</h1>

<!-- ========================================================= -->
<!-- Part 0: Prompting & Sampling -->
<!-- ========================================================= -->
<section id="part-0">
<h2>Part 0 – Prompting and Sampling</h2>

To demonstrate the usage of the DeepFloyd IF diffusion model, below are a few examples of different prompts using 20 inference steps with stage 1 of the model, which generates images at 64x64 resolution:

<div class="subsection" id="part-0-images">
<h3>Images generated with num_inference_steps=20</h3>

<div class="image-row">
<figure>
<img src="images/64vs256/01_64px_20.png" alt="01_64px_20.png" />
<figcaption>Prompt 1 – 'a photo of a hipster barista'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/02_64px_20.png" alt="02_64px_20.png" />
<figcaption>Prompt 2 – 'a man wearing a hat'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/03_64px_20.png" alt="03_64px_20.png" />
<figcaption>Prompt 3 – 'a rocket ship'<br /></figcaption>
</figure>
</div>
</div>
 
Using stage 2, we can take the output of stage 1 and upscale them to 256x256 resolution:

<div class="subsection" id="part-0-images">
<div class="image-row">
<figure>
<img src="images/64vs256/01_256px_20.png" alt="01_256px_20.png" />
<figcaption>Prompt 1 – 'a photo of a hipster barista'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/02_256px_20.png" alt="02_256px_20.png" />
<figcaption>Prompt 2 – 'a man wearing a hat'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/03_256px_20.png" alt="03_256px_20.png" />
<figcaption>Prompt 3 – 'a rocket ship'<br /></figcaption>
</figure>
</div>
</div>

By increasing the inference steps, we can generate higher quality images at cost of more compute time. Below are the stage 2 outputs with the number of inference steps at 100:

<div class="subsection" id="part-0-images">
<h3>Images generated with num_inference_steps=100</h3>

<div class="image-row">
<figure>
<img src="images/64vs256/01_256px_100.png" alt="01_256px_100.png" />
<figcaption>Prompt 1 – 'a photo of a hipster barista'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/02_256px_100.png" alt="02_256px_100.png" />
<figcaption>Prompt 2 – 'a man wearing a hat'<br /></figcaption>
</figure>
<figure>
<img src="images/64vs256/03_256px_100.png" alt="03_256px_100.png" />
<figcaption>Prompt 3 – 'a rocket ship'<br /></figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.1: Forward Process-->
<!-- ========================================================= -->
<section id="part-1-1">
<h2>Part 1.1 – Implementing the forward process</h2>

To start, we have the original Campanile image at 64px:
<div class="image-row">
<figure>
<img src="images/campanile.png" alt="campanile.png" />
</figure>
</div>

For the forward function, we can use <code>alphas_cumprod[t]</code> to obtain the noise coefficient at timestamp <code>t</code>, and <code>torch.randn_like</code> to get &epsilon; &isin; [0, 1), allowing us to compute <code>im_noisy</code>. Below are examples of the Campanile at noise timestamps 250, 500, and 750:

<div class="subsection">
<h3>Campanile at Different Noise Levels</h3>
<div class="image-row">
<figure>
<img src="images/250500750/campanile_250noise.png" alt="campanile_250noise.png" />
<figcaption>Campanile at t = 250</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_500noise.png" alt="campanile_500noise.png" />
<figcaption>Campanile at t = 500</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_750noise.png" alt="campanile_750noise.png" />
<figcaption>Campanile at t = 750</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.2: Gaussian Denoising -->
<!-- ========================================================= -->
<section id="part-1-2">
<h2>Part 1.2 – Classical Denoising</h2>

In order to try to revert the image with noise, we can try the classical method for denoising, namely Gaussian filtering. However, with high noise the effect is limited:

<div class="subsection">
<h3>Noisy vs Gaussian-Denoised Campanile</h3>

<h4>t = 250</h4>
<div class="image-row">
<figure>
<img src="images/250500750/campanile_250noise.png" alt="campanile_250noise.png" />
<figcaption>Noisy Campanile (t = 250)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_250denoise_gaussian.png" alt="campanile_250denoise_gaussian.png" />
<figcaption>Gaussian denoised (t = 250)</figcaption>
</figure>
</div>

<h4>t = 500</h4>
<div class="image-row">
<figure>
<img src="images/250500750/campanile_500noise.png" alt="campanile_500noise.png" />
<figcaption>Noisy Campanile (t = 500)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_500denoise_gaussian.png" alt="campanile_500denoise_gaussian.png" />
<figcaption>Gaussian denoised (t = 500)</figcaption>
</figure>
</div>

<h4>t = 750</h4>
<div class="image-row">
<figure>
<img src="images/250500750/campanile_750noise.png" alt="campanile_750noise.png" />
<figcaption>Noisy Campanile (t = 750)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_750denoise_gaussian.png" alt="campanile_750denoise_gaussian.png" />
<figcaption>Gaussian denoised (t = 750)</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.3: One-Step Denoising -->
<!-- ========================================================= -->
<section id="part-1-3">
<h2>Part 1.3 – Implementing One Step Denoising</h2>

A much more effective method is to use a pretrained diffusion model. Using <code>stage_1.unet</code>, we can estimate the amount of noise in the noisy image. With the forward equation, we can solve for <code>x<sub>0</sub></code> (the original image) given the timestamp <code>t</code>:

<div class="subsection">
<pre><code>at_x0 = im_noisy_cpu - (1 - alpha_cumprod).sqrt() * noise_est
original_im = at_x0 / alpha_cumprod.sqrt()</code></pre>
</div>

Below are a comparison the original, noisy, and the estimate of the original image for <code>t</code> &isin; [250, 500, 750]:

<div class="subsection">
<h3>Original, Noisy, One-Step Estimate (t = 250, 500, 750)</h3>

<h4>t = 250</h4>
<div class="image-row">
<figure>
<img src="images/campanile.png" alt="campanile.png" />
<figcaption>Original Campanile</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_250noise.png" alt="campanile_250noise.png" />
<figcaption>Noisy (t = 250)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_250denoise_onestep.png" alt="campanile_250denoise_onestep.png" />
<figcaption>One-step estimate of original (t = 250)</figcaption>
</figure>
</div>

<h4>t = 500</h4>
<div class="image-row">
<figure>
<img src="images/campanile.png" alt="campanile.png" />
<figcaption>Original Campanile</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_500noise.png" alt="campanile_500noise.png" />
<figcaption>Noisy (t = 500)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_500denoise_onestep.png" alt="campanile_500denoise_onestep.png" />
<figcaption>One-step estimate of original (t = 500)</figcaption>
</figure>
</div>

<h4>t = 750</h4>
<div class="image-row">
<figure>
<img src="images/campanile.png" alt="campanile.png" />
<figcaption>Original Campanile</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_750noise.png" alt="campanile_750noise.png" />
<figcaption>Noisy (t = 750)</figcaption>
</figure>
<figure>
<img src="images/250500750/campanile_750denoise_onestep.png" alt="campanile_750denoise_onestep.png" />
<figcaption>One-step estimate of original (t = 750)</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.4: Iterative Denoising-->
<!-- ========================================================= -->
<section id="part-1-4">
<h2>Part 1.4 – Iterative Denoising</h2>

Instead of using one step, we can obtain better results by iterativly denoising from step <code>t</code> until step 0. However, this means running the diffusion model 1000 times in the worst case, which is slow and costly.<br>
<br>
Fortunately, we can speed up the computation by first defining series of strided timestamps, starting at close to 1000 and ending at 0. For the examples below, we will use <code>strided_timestamps = [990, 960, ..., 30, 0]</code>. Then, we can use the formula

<div class="image-row">
<figure>
<img src="images/equation.png" alt="equation.png" />
</figure>
</div>

to compute <code>x</code> at timestamp <code>T</code>, where <code>T</code> (or <code>prev_t</code>) is the next timestamp after the current timestamp <code>t</code> in <code>strided_timestamps</code>. First, we compute the constants:

<div class="subsection">
<pre><code>alpha_cumprod = alphas_cumprod[t]
alpha_cumprod_prev = alphas_cumprod[prev_t]
alpha_t = alpha_cumprod / alpha_cumprod_prev
beta_t = 1 - alpha_t</code></pre>
</div>

Then, we can compute <code>x<sub>T</sub></code> by using the one-step estimate of <code>x<sub>0</sub></code> as follows:

<div class="subsection">
<pre><code>x_0 = (image - (1 - alpha_cumprod).sqrt() * noise_est) / alpha_cumprod.sqrt()
term_1 = alpha_cumprod_prev.sqrt() * beta_t
term_2 = alpha_t.sqrt() * (1 - alpha_cumprod_prev)
pred_pi_nonoise = (term_1 * x_0 + term_2 * image) / (1 - alpha_cumprod)
pred_prev_image = add_variance(predicted_variance, t, pred_pi_nonoise)</code></pre></div>

Below are some visualizations for the iterative denoising process:

<div class="subsection">
<h3>Denoising Loop Visualizations (i_start = 10)</h3>

<p>Noisy Campanile at t = timestep[10]:</p>
<figure>
<img src="images/ddpm/DDPM_0x5.png" alt="DDPM_0x5.png" />
<figcaption>Initial noisy Campanile (i_start = 10)</figcaption>
</figure>

<h4>Every 5th loop of iterative denoising</h4>
<div class="image-row">
<figure>
<img src="images/ddpm/DDPM_0x5.png" alt="DDPM_0x5.png" />
<figcaption>Step 0 (initial)</figcaption>
</figure>
<figure>
<img src="images/ddpm/DDPM_1x5.png" alt="DDPM_1x5.png" />
<figcaption>Step 5</figcaption>
</figure>
<figure>
<img src="images/ddpm/DDPM_2x5.png" alt="DDPM_2x5.png" />
<figcaption>Step 10</figcaption>
</figure>
<figure>
<img src="images/ddpm/DDPM_3x5.png" alt="DDPM_3x5.png" />
<figcaption>Step 15</figcaption>
</figure>
<figure>
<img src="images/ddpm/DDPM_4x5.png" alt="DDPM_4x5.png" />
<figcaption>Step 20</figcaption>
</figure>
</div>

<h4>Final predicted clean images</h4>
<div class="image-row">
<figure>
<img src="images/ddpm/final_ddpm.png" alt="final_ddpm.png" />
<figcaption>Iterative denoising clean image</figcaption>
</figure>
<figure>
<img src="images/ddpm/final_onestep.png" alt="final_onestep.png" />
<figcaption>One-step denoising (from part 1.3)</figcaption>
</figure>
<figure>
<img src="images/ddpm/final_gaussianblur.png" alt="final_gaussianblur.png" />
<figcaption>Gaussian blur baseline (from part 1.2)</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.5: Unconditional Sampling -->
<!-- ========================================================= -->
<section id="part-1-5">
<h2>Part 1.5 – Unconditional Sampling</h2>

<div class="subsection">
<h3>Code: Sampling from Stage 1</h3>
<pre><code># TODO
# Example:
# stage_1_output = stage_1(
# prompt_embeds=prompt_embeds_null,
# negative_prompt_embeds=...,
# num_inference_steps=...,
# output_type="pt",
# ).images</code></pre>
</div>

<div class="subsection">
<h3>5 Sampled Images</h3>
<div class="image-row">
<figure>
<img src="images/part1_5_sample_1.png" alt="Sample 1" />
<figcaption>Sample 1</figcaption>
</figure>
<figure>
<img src="images/part1_5_sample_2.png" alt="Sample 2" />
<figcaption>Sample 2</figcaption>
</figure>
<figure>
<img src="images/part1_5_sample_3.png" alt="Sample 3" />
<figcaption>Sample 3</figcaption>
</figure>
<figure>
<img src="images/part1_5_sample_4.png" alt="Sample 4" />
<figcaption>Sample 4</figcaption>
</figure>
<figure>
<img src="images/part1_5_sample_5.png" alt="Sample 5" />
<figcaption>Sample 5</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.6: CFG Sampling -->
<!-- ========================================================= -->
<section id="part-1-6">
<h2>Part 1.6 – Classifier-Free Guidance (CFG)</h2>

<div class="subsection">
<h3>Code: iterative_denoise_cfg</h3>
<pre><code># TODO
# def iterative_denoise_cfg(im_noisy, i_start, timesteps, prompt_embeds, uncond_prompt_embeds, scale=7, ...):
# # Use CFG noise estimate:
# # noise_est_cfg = uncond_noise_est + scale * (noise_est - uncond_noise_est)
# return clean_image</code></pre>
</div>

<div class="subsection">
<h3>5 Images with Prompt "a high quality photo" (γ = 7)</h3>
<div class="image-row">
<figure>
<img src="images/part1_6_cfg_1.png" alt="CFG sample 1" />
<figcaption>CFG sample 1</figcaption>
</figure>
<figure>
<img src="images/part1_6_cfg_2.png" alt="CFG sample 2" />
<figcaption>CFG sample 2</figcaption>
</figure>
<figure>
<img src="images/part1_6_cfg_3.png" alt="CFG sample 3" />
<figcaption>CFG sample 3</figcaption>
</figure>
<figure>
<img src="images/part1_6_cfg_4.png" alt="CFG sample 4" />
<figcaption>CFG sample 4</figcaption>
</figure>
<figure>
<img src="images/part1_6_cfg_5.png" alt="CFG sample 5" />
<figcaption>CFG sample 5</figcaption>
</figure>
</div>
</div>
</section>

<!-- ========================================================= -->
<!-- Part 1.7: SDEdit-style Edits & Inpainting-->
<!-- ========================================================= -->
<section id="part-1-7">
<h2>Part 1.7 – SDEdit-Style Edits and Inpainting</h2>

<!-- 1.7: Edits of Campanile -->
<div class="subsection">
<h3>1.7.1 – Edits of the Campanile (Noise Levels [1, 3, 5, 7, 10, 20])</h3>
<p>Conditional text prompt: <strong>"a high quality photo"</strong></p>

<div class="image-row">
<figure>
<img src="images/part1_7_campanile_edit_level1.png" alt="Campanile edit level 1" />
<figcaption>Noise level index 1</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_edit_level3.png" alt="Campanile edit level 3" />
<figcaption>Noise level index 3</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_edit_level5.png" alt="Campanile edit level 5" />
<figcaption>Noise level index 5</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_edit_level7.png" alt="Campanile edit level 7" />
<figcaption>Noise level index 7</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_edit_level10.png" alt="Campanile edit level 10" />
<figcaption>Noise level index 10</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_edit_level20.png" alt="Campanile edit level 20" />
<figcaption>Noise level index 20</figcaption>
</figure>
</div>
</div>

<!-- 1.7: Edits of own test images -->
<div class="subsection">
<h3>1.7.2 – Edits of 2 Own Test Images</h3>

<h4>Test Image 1</h4>
<div class="image-row">
<figure>
<img src="images/part1_7_own1_original.png" alt="Own test image 1 original" />
<figcaption>Original image 1</figcaption>
</figure>
<figure>
<img src="images/part1_7_own1_edit_level1.png" alt="Own image 1 edit level 1" />
<figcaption>Noise index 1</figcaption>
</figure>
<figure>
<img src="images/part1_7_own1_edit_level3.png" alt="Own image 1 edit level 3" />
<figcaption>Noise index 3</figcaption>
</figure>
<!-- add 5, 7, 10, 20 -->
</div>

<h4>Test Image 2</h4>
<div class="image-row">
<figure>
<img src="images/part1_7_own2_original.png" alt="Own test image 2 original" />
<figcaption>Original image 2</figcaption>
</figure>
<figure>
<img src="images/part1_7_own2_edit_level1.png" alt="Own image 2 edit level 1" />
<figcaption>Noise index 1</figcaption>
</figure>
<!-- add 3, 5, 7, 10, 20 -->
</div>
</div>

<!-- 1.7: Web image edits -->
<div class="subsection">
<h3>1.7.3 – Edits of a Web Image</h3>
<p>Describe the source image: <!-- TODO --></p>

<div class="image-row">
<figure>
<img src="images/part1_7_web_original.png" alt="Web image original" />
<figcaption>Original web image</figcaption>
</figure>
<figure>
<img src="images/part1_7_web_edit_level1.png" alt="Web image edit level 1" />
<figcaption>Noise index 1</figcaption>
</figure>
<!-- add 3, 5, 7, 10, 20 (+ extras if any) -->
</div>
</div>

<!-- 1.7: Hand-drawn image edits -->
<div class="subsection">
<h3>1.7.4 – Edits of 2 Hand-Drawn Images</h3>

<h4>Hand Drawn Image 1</h4>
<div class="image-row">
<figure>
<img src="images/part1_7_hand1_original.png" alt="Hand-drawn 1 original" />
<figcaption>Original hand-drawn image 1</figcaption>
</figure>
<figure>
<img src="images/part1_7_hand1_edit_level1.png" alt="Hand-drawn 1 edit level 1" />
<figcaption>Noise index 1</figcaption>
</figure>
<!-- add 3, 5, 7, 10, 20 -->
</div>

<h4>Hand Drawn Image 2</h4>
<div class="image-row">
<figure>
<img src="images/part1_7_hand2_original.png" alt="Hand-drawn 2 original" />
<figcaption>Original hand-drawn image 2</figcaption>
</figure>
<figure>
<img src="images/part1_7_hand2_edit_level1.png" alt="Hand-drawn 2 edit level 1" />
<figcaption>Noise index 1</figcaption>
</figure>
<!-- add 3, 5, 7, 10, 20 -->
</div>
</div>

<!-- 1.7: Inpainting -->
<div class="subsection">
<h3>1.7.5 – Inpainting</h3>

<h4>Code: inpaint function</h4>
<pre><code># TODO
# def inpaint(original_image, mask, prompt_embeds, uncond_prompt_embeds, timesteps, scale=7, ...):
# ...
# return inpainted_image</code></pre>

<h4>Campanile Inpainting</h4>
<div class="image-row">
<figure>
<img src="images/part1_7_campanile_inpaint_mask.png" alt="Campanile inpaint mask" />
<figcaption>Campanile with inpaint mask overlay</figcaption>
</figure>
<figure>
<img src="images/part1_7_campanile_inpaint_result.png" alt="Campanile inpaint result" />
<figcaption>Inpainted Campanile</figcaption>
</figure>
</div>

<h4>Inpainting on 2 of Your Own Images</h4>
<h5>Own Image 1</h5>
<div class="image-row">
<figure>
<img src="images/part1_7_own1_inpaint_mask.png" alt="Own image 1 inpaint mask" />
<figcaption>Own image 1 – mask</figcaption>
</figure>
<figure>
<img src="images/part1_7_own1_inpaint_result.png" alt="Own image 1 inpaint result" />
<figcaption>Own image 1 – inpainted</figcaption>
</figure>
</div>

<h5>Own Image 2</h5>
<div class="image-row">
<figure>
<img src="images/part1_7_own2_inpaint_mask.png" alt="Own image 2 inpaint mask" />
<figcaption>Own image 2 – mask</figcaption>
</figure>
<figure>
<img src="images/part1_7_own2_inpaint_result.png" alt="Own image 2 inpaint result" />
<figcaption>Own image 2 – inpainted</figcaption>
</figure>
</div>
</div>

</section>

</body>
</html>
