<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CS 180 Project 3A</title>
</head>
<body>
<header>
<h1>Project 3A: Image Warpping and Mosaicing</h1>
<div align="center">
<p>
by Daniel Cheng | October 16, 2025
</p>
</div>
</header>

<main>
<h3>Part 1</h3>

<p>
Below are 2 examples of set images that we can warp to form a larger combined image.
</p>

<div style="display:flex; flex-wrap:wrap; justify-content:center; text-align:center;">

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_left.png" alt="img_left.png">
</figure>

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_center.png" alt="img_center.png">
</figure>

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_right.png" alt="img_right.png">
</figure>

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_upleft.png" alt="img_upleft.png">
</figure>

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_upcenter.png" alt="img_upcenter.png">
</figure>

<figure style="flex: 1 0 30%; margin:12px;">
<img src="images/img_upright.png" alt="img_upright.png">
</figure>
</div>
<hr>

<h3>Part 2</h3>

<p>
To combine the images above, we can perform a projective transformation on one of the images such that it will match the other. Because the only change in amera position is rotation, we can compute a homography between 4 chosen points on 2 images that correspond to the same object. In the first example, we will choose the 4 points that maps to the rightmost window of the building.
</p>

<div style="display:flex; flex-wrap:wrap; justify-content:center; text-align:center;">

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Center (destination) image</figcaption>
<img src="images/img_center.png" alt="img_center.png" width="50%">
</figure>

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Right (source) image</figcaption>
<img src="images/img_right.png" alt="img_right.png" width="50%">
</figure>
</div>

<p>
Using the points
</p>

<pre><code>
xy1, xy2, xy3, xy4, uv1, uv2, uv3, uv4 = (
    (303.4064, 446.3877),
    (449.93048, 419.11496),
    (447.79144, 660.29144),
    (322.123, 702.5374),
    (689.78, 411.4477),
    (851.77454, 410.35315),
    (802.5195, 661.00684),
    (665.69977, 661.00684)
)
</code></pre>

<p>
we can obtain the system of equations
</p>
<div align="center">
<img src="images/equation.png" alt="equation.png" width="50%">
</div>
<p>
which produces the homography matrix
</p>
<pre><code>
[[ 5.07543229e-01 -9.06493462e-02  4.94054627e+02]
 [-5.71786088e-02  8.91384807e-01 -1.81376979e+01]
 [-5.12480937e-04  8.13734006e-05  1.00000000e+00]]
</code></pre>

<p>
This will allow us to warp the right image such that the window above will match the one in the center image.
</p>
<hr>

<h3>Part 3</h3>
<p>
With our homography matrix <i>H</i>, we can theoretically directly map the source image to the destination. However, the mapped pixels would not be all integers, which would result in pixels that are not mapped. TO solve this issue, we can use inverse mapping, by first starting with a destination pixel as a vector in the form [<i>u</i>, <i>v</i>, 1]<sup>T</sup> and multiplying the inverse <i>H<sup>-1</sup></i> to obtain the pixel from the source image that should be mapped to the destination pixel, and use 2 methods for computing the color of the pixel from the source: Nearest Neighbor and Bilinear Interpolation.<br>
<br>
To compute the bounds of where to take inverse mapping from, we can transform the coordinates (-0.5, -0.5), (<i>W</i> - 0.5, -0.5), (<i>W</i>, <i>H</i>), and (-0.5, <i>H</i> - 0.5) to provide an upper bound of the transfromed image. We can then round the result to the closest number in &#8484; + 0.5, which is equivalent to casting the result to an integer, since we only need the integer coordinates. Below is a comparison of the 2 methods.
</p>

<div align="center">
<figcaption style="margin-bottom:6px;">Original</figcaption>
<img src="images/img_right.png" alt="img_right.png" width="25%">
</div>

<div style="display:flex; flex-wrap:wrap; justify-content:center; text-align:center;">

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Transformed using NN Interpolation</figcaption>
<img src="images/imwraped_nearestneighborR.jpg" alt="imwraped_nearestneighborR.jpg" width="50%">
</figure>

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Transformed using Bilinear Interpolation</figcaption>
<img src="images/imwraped_bilinearR.jpg" alt="imwraped_bilinearR.jpg" width="50%">
</figure>
</div>

<p>
From the above, we can see that the Nearest Neighbor method introduces jagged edges due to only sampling from exact pixel values, while the Bilinear method produces a smoother image.
</p>

<p>
We can also perform image rectification using this tool by transforming a non-rectangular region into a rectangular one. Because we only care about the pixels in the selected region, we can precompute the final dimensions of the rectangle and only perform inverse mapping on the given region. Below are 2 examples of rectifying an image:
</p>

<div style="display:flex; flex-wrap:wrap; justify-content:center; text-align:center;">

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Original</figcaption>
<img src="images/evacuationplan.png" alt="evacuationplan.png" width="50%">
</figure>

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Rectified</figcaption>
<img src="images/ep_rectif.jpg" alt="ep_rectif.jpg" width="50%">
</figure>
</div>

<div style="display:flex; flex-wrap:wrap; justify-content:center; text-align:center;">

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Original</figcaption>
<img src="images/cs170.png" alt="cs170.png" width="50%">
</figure>

<figure style="flex: 1 0 40%; margin:12px;">
<figcaption style="margin-bottom:6px;">Rectified</figcaption>
<img src="images/cs170_rectif.jpg" alt="cs170_rectif.jpg" width="50%">
</figure>
</div>
<hr>

<div align="center">
<a href="https://cjxthecoder.github.io">cjxthecoder</a> | <a href="https://github.com/cjxthecoder">GitHub</a> | <a href="https://www.linkedin.com/in/daniel-cheng-71b475279">LinkedIn</a>
</div>
<hr>

<h3>Part 4</h3>
<p>
With our homography matrix <i>H</i>, we can theoretically directly map the source image to the destination. However, the mapped pixels would not be all integers, which would result in pixels that are not mapped. TO solve this issue, we can use inverse mapping, by first starting with a destination pixel as a vector in the form [<i>u</i>, <i>v</i>, 1]<sup>T</sup> and multiplying the inverse <i>H<sup>-1</sup></i> to obtain the pixel from the source image that should be mapped to the destination pixel, and use 2 methods for computing the color of the pixel from the source: Nearest Neighbor and Bilinear Interpolation.<br>
<br>
To compute the bounds of where to take inverse mapping from, we can transform the coordinates (-0.5, -0.5), (<i>W</i> - 0.5, -0.5), (<i>W</i>, <i>H</i>), and (-0.5, <i>H</i> - 0.5) to provide an upper bound of the transfromed image. We can then round the result to the closest number in &#8484; + 0.5, which is equivalent to casting the result to an integer, since we only need the integer coordinates. Below is a comparison of the 2 methods.
</p>

</main>
</body>
</html>
